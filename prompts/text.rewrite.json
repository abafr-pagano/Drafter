{
  "model": "llama3.1:8b",
  "temperature": 0.1,
  "context_window": 2048,
  "stream": false
}
